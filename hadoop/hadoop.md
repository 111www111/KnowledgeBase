# Hadoop 

前言：

这篇文章已经是我第二篇记录关于Hadoop的文章了，为了给目前项目组提供更优质的存储方案而记录

## 1. 关于Hadoop生态部分

关于Hadoop的生态，无非就是自身重要的几个组件+周边的外围生态

- HDFS：Hadoop的分布式文件系统，解决分布式文件的存储问题
- MapReduce：Hadoop的分布式运算框架，降低分布式运算的开发难度，提升效率
- Yarn：Hadoop的资源调度系统，解决程序的启动资源调度以及资源回收

再加上Hadoop强大的外围生态，解决各种问题

- Hive：基于HDFS与MapReduce封装的SQL 工具
- HBase：基于HDFS实现的分布式NoSQL数据库
- Flume：分布式日志采集系统
- Sqoop：数据迁移工具（关系型数据库<==>Hadoop存储系统）

这些组件配合HDFS 解决了大部分大数据使用场景的问题，也渐渐演变成了成熟的大数据体系。

## 2. HDFS 分布式文件系统的概念

### 2.1 简介

HDFS是一个分布式文件系统（管理系统），用于提供文件的读取服务，写入服务，查看目录信息服务等等，而这些文件处于多个文件主机上。

我们先来简单介绍一下，什么是分布式文件系统，首先把目光转移到我们常见的windows上面![1681224521679](C:\Users\13169\Desktop\KnowledgeBase\hadoop\assets\1681224521679.png)

我们可以看到，目前windows使用的文件系统是NTFS，还有早期的FAT32，都是一种类型的文件管理系统的简称，而这些文件管理系统并不能实现跨机器的文件操作，例如删除，写入，目录信息服务等，再此处理念之上，Hadoop提供了HDFS文件管理系统以解决该问题。

假设此时我们有三台机器，三台机器均安装HDFS的文件系统，那么在这个集群上我们可以从一个宏观的角度假设这是一个整体，然后这个整体对外提供一个文件管理的功能。![1681224532604](C:\Users\13169\Desktop\KnowledgeBase\hadoop\assets\1681224532604.png)

如上图所示，此时 HDFS会抽象出来一个目录树，而这个目录是不是我们传统文件存储系统的目录树，抽象的目录并不存在，但是实际的文件确实存在的，例如如中的**a.txt**  可能存放在linux3中，也可能存放在linux2中 

![1681213815564](C:\Users\13169\Desktop\KnowledgeBase\hadoop\assets\1681224540602.png)

对开发者来说，我们可能此时并不知道 a.txt 的文件实体处于哪台机器中，而HDFS从自身维护的抽象目录树中可以去获取这个实体的文件，从而读取信息提供给开发者，所以我们可以认知到，**虚拟的目录树会去记录文件所处路径，机器信息**等等，当你读取这个文件的时候，通过抽象目录所保存的信息去读取实体文件，而对应的，实体存放数据的机器上应该有一个对应的程序去回应虚拟目录树的调用，将程序“递”给目录完成响应，从而完成这一个分布式文件的操作，那么再次引出了一个新的概念。Data Node 与 Name Node

从上面的例子不难看出 Name Node  本质上是作为资源的目录记录，而实际的Data Node则是具体的文件存放节点，将文件的信息和自己的节点信息存放在Name Node ，以方便查找,二者相互配合，完成抽象目录的维护。

那么HDFS中的与运行逻辑为，当客户端需要获取文件的时候，首先需要找Name Node 机器的端口（默认通讯端口为**9000**）,获取目录树通过Name Node 获取 Data Node中的具体数据，完成交互。

当然，HDFS不仅仅如此，面对体积较大的文件的时候，HDFS会将数据切成一块一块（block），我们可以限定一个我们可以接受的块（例如限制一块最大为128M），然后均摊服务器的压力，举个例子，我们限制了block的上限为128M，那么当一个300M的文件存放时，HDFS会将他切割

| 块名称    | 大小 |
| --------- | ---- |
| BLK_00001 | 128M |
| BLK_00002 | 128M |
| BLK_00003 | 44M  |

随后分布存放，然后将每块的**顺序以及节点信息，目录**存放在Name Node。为了避免Data Node的单点故障导致某一个Block无法读取，在存储时我们会将每一个块存放在其他机器上一份作为备份（可以设定，默认保留两个块备份），防止Date Node 的突然暴毙产生的数据问题，以便解决单点故障。

### 2.2 总结：

Hadoop更适合一次存储，多次读取的存储模式，BUT。这种存储模式也有弊

1.并不支持低延时数据访问,例如，毫秒级的存储数据，肯定是不如MySQL的，重在量级，so。

2.无法高效的对小文件进行存储,存储大量小文件的话，会占用Name Node大量的内存来存储文件和块信息，不可取！且小文件存储的寻址时间会超过读取时间，这一点也算是违反了HDFS的设计目标。

3.不支持并发的文件写入，不支持文件修改,一个文件只允许有一个写，不存在多个线程。仅支持append追加，不支持修改。

### 2.3 相关理念

1.NameNode -> 其实就是Master

​	负责管理HDFS名称空间，负责配置副本策略，负责管理数据块Block的映射信息

2.DataNode -> 干活的打工仔

​	负责存储实际的数据块，执行数据的读写操作。

3.Client -> 客户端

​	负责文件切分，文件上传HDFS时候，客户端会切分文件，负责与Name Node交互，获取文件位置，与Data Node交互，读取或写入数据，提供Name Node格式化

4.SecondaryNameNode（2nn）

​	备选，但并不是Name Node的热备，Name Node挂掉不会立马替换，建议搭建高可用，负责辅助Name Node，分担其工作量，紧急情况下可以恢复Name Node

附属一张HDFS的组成架构图：![1681215988980](C:\Users\13169\Desktop\KnowledgeBase\hadoop\assets\1681224560334.png)

### 2.4 关于HDFS的Shell相关操作 

基本语法 hadoop fs 具体命令  or  hdfs fs 具体命令 这两个是完全相同的 

常用命令大全： 

```shell
hdfs fs help xxx
#上传
#剪切上传！
hadoop fs -moveFromLocal /文件路径 /hadoop路径
#复制上传
hadoop fs -copyFromLocal /文件路径 /hadoop路径
#put = 复制上传ss
hadoop fs -put /文件路径 /hadoop路径
#追加一个文件到已经存在的文件末尾
hadoop fs -appendToFile /文件路径 /追加文件路径

#下载 这俩是一样的
hadoop fs -get /hadoop文件路径 /保存路径
hadoop fs -copyToLocal /hadoop文件路径 /保存路径

#直接操作
#-ls 显示目录
hadoop fs -ls /
#-cat 显示内容
hadoop fs -cat /目录
#此处，-mkdir，-rm，-cp，-mv与Linux一致，不举例
#-du 统计信息 展示 文件大小，文件副本数，路径
hadoop fs -du -h /文件
```

